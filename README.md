# Developing a Fine-Tuned Solution for Solving Numerical Linear Algebra Problems Using Large Language Models (NLA Project)

This repository presents a research project focused on evaluating, fine-tuning, and deploying Large Language Models (LLMs) to enhance mathematical reasoning in the domain of **Numerical Linear Algebra (NLA)**.

The project follows a systematic pipeline involving dataset preparation, multi-model evaluation, comparative analysis, domain-specific fine-tuning, and deployment as an application.

---
## ðŸ¤— Hugging Face Model

The fine-tuned Numerical Linear Algebra (NLA) model is publicly available on Hugging Face:

ðŸ”— **Model Repository:**  
https://huggingface.co/Dilaksan/NLA/tree/main

## Project Overview

The methodology adopted in this project consists of the following stages:

1. Preparation of an NLA questionâ€“answer dataset  
2. Evaluation of multiple baseline LLMs  
3. Comparative analysis using semantic similarity and rank-based metrics  
4. Selection of the best-performing model  
5. Fine-tuning using domain-specific NLA data  
6. Deployment of the fine-tuned model as an application for solving NLA problems  

---

## Project Structure

```
nla/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ answers/
â”‚   â”‚   â”œâ”€â”€ book/answers.csv
â”‚   â”‚   â”œâ”€â”€ deepseek/deepseek-r1-0528-1.csv
â”‚   â”‚   â”œâ”€â”€ google/gemini-2.5-pro1.csv
â”‚   â”‚   â”œâ”€â”€ new_model/answers.csv
â”‚   â”‚   â”œâ”€â”€ openai/o4-mini1.csv
â”‚   â”‚   â””â”€â”€ x-ai/grok-3-mini-beta1.csv
â”‚   â””â”€â”€ questions/questions.csv
â”‚
â”œâ”€â”€ finetune/
â”‚   â”œâ”€â”€ code/finetune.ipynb
â”‚   â””â”€â”€ dataset/
â”‚       â”œâ”€â”€ final_answers.csv
â”‚       â””â”€â”€ final_questions.csv
â”‚
â”œâ”€â”€ nla_tutor/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ functions.py
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ main2.py
â”‚       â”œâ”€â”€ visual_compare_llms.py
â”‚       â”œâ”€â”€ visual_compare_llms_vs_new_model.py
â”‚       â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ report/llm_analysis_results.csv
â”œâ”€â”€ img/
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## Models Compared

- OpenAI â€“ **o4-mini**  
- Google â€“ **Gemini 2.5 Pro**  
- DeepSeek â€“ **DeepSeek-R1-0528**  
- xAI â€“ **Grok-3 Mini (Beta)**  
- Custom Fine-Tuned Model â€“ **new_model**  
- Baseline â€“ **Textbook (ground-truth) answers**


---

## Evaluation Methodology

- Cosine similarity for semantic alignment between generated and ground-truth solutions  
- Rank-based evaluation to assess relative model accuracy per question  
- Visualization of performance comparisons across baseline and fine-tuned models  

---

## Outcome

Based on comparative evaluation, the best-performing baseline model is selected and fine-tuned using domain-specific NLA data.  
The fine-tuned model demonstrates improved semantic and structural alignment with expert-annotated solutions and is deployed as an application for solving Numerical Linear Algebra problems.

---

## License

This project is intended for **research and academic use**.  
Please cite this work appropriately if used in publications.

